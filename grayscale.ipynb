{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef14637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#手の表面を1フレームずつ画像に変換処理--(pro1)\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "inputname=[\"araiomote\",\"araiura\",\"gotoomote\",\"gotoura\",\"isiiomote\",\"isiiura\",\"mimuraomote\",\"mimuraura\",\n",
    "      \"mineomote\",\"mineura\",\"nakaomote\",\"nakaura\",\"okuomote\",\"okuura\",\"saitouhideakiomote\",\n",
    "      \"saitouhideakiura\",\"saitouryougaomote\",\"saitouryougaura\",\"sakumaomote\",\"sakumaura\",\n",
    "      \"tanakaomote\",\"tanakaura\",\"tochiomote\",\"tochiura\",\"tokuyamaomote\",\"tokuyamaura\",\n",
    "      \"watanabeomote\",\"watanabeura\",\"yamaguchiomote\",\"yamaguchiura\"]\n",
    "output=[\"arai/omote\",\"arai/ura\",\"gotou/omote\",\"gotou/ura\",\"isii/omote\",\"isii/ura\",\n",
    "       \"mimura/omote\",\"mimura/ura\",\"mine/omote\",\"mine/ura\",\"nakamura/omote\",\"nakamura/ura\",\n",
    "       \"okutani/omote\",\"okutani/ura\",\"saitouhide/omote\",\"saitouhide/ura\",\"saitouryou/omote\",\n",
    "       \"saitouryou/ura\",\"sakuma/omote\",\"sakuma/ura\",\"tanaka/omote\",\"tanaka/ura\",\"tochikubo/omote\",\n",
    "       \"tochikubo/ura\",\"tokuyama/omote\",\"tokuyama/ura\",\"watanabe/omote\",\"watanabe/ura\",\n",
    "       \"yamaguchi/omote\",\"yamaguchi/ura\"]\n",
    "'''\n",
    "inputname=[\"araiomote\",\"araiura\",\"gotoomote\",\"gotoura\",\"isiiomote\",\"isiiura\",\"mimuraomote\",\"mimuraura\",\n",
    "      \"mineomote\",\"mineura\",\"nakaomote\",\"nakaura\",\"okuomote\",\"okuura\",\"tochiomote\",\"tochiura\"]\n",
    "output=[\"arai/omote\",\"arai/ura\",\"gotou/omote\",\"gotou/ura\",\"isii/omote\",\"isii/ura\",\n",
    "       \"mimura/omote\",\"mimura/ura\",\"mine/omote\",\"mine/ura\",\"nakamura/omote\",\"nakamura/ura\",\n",
    "       \"okutani/omote\",\"okutani/ura\",\"tochikubo/omote\",\"tochikubo/ura\"]\n",
    "'''\n",
    "for i in range(30):#変更必要\n",
    "    save_dir=\"./grayhands/\"+str(output[i])\n",
    "    cap=cv2.VideoCapture(\"./MOV/\"+str(inputname[i])+\".MOV\")\n",
    "    if not cap.isOpened():\n",
    "        sys.exit()\n",
    "    n= 0\n",
    "    while True:\n",
    "        # read()でフレーム画像が読み込めたかを示すbool、フレーム画像の配列ndarrayのタプル\n",
    "        is_image,frame_img = cap.read()\n",
    "        if is_image:\n",
    "            # 画像を保存\n",
    "            outfile=save_dir+\"/\"+str(n)+\".jpg\"\n",
    "            #グレイスケール化\n",
    "            im_gray = cv2.cvtColor(frame_img, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imwrite(outfile, im_gray)\n",
    "        else:\n",
    "            # フレーム画像が読込なかったら終了\n",
    "            break\n",
    "        n += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(str(output[i])+\":ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f30868",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#画像ファイルを読み込んでNumpy形式に変換--(pro2)\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os,glob,random\n",
    "\n",
    "outfile=\"./num16graylight320px.npz\"#変更必要\n",
    "max_photo=40000\n",
    "photo_size=320#変更必要\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "def main():\n",
    "    glob_files(\"./grayhands/mine/omote\",0)\n",
    "    glob_files(\"./grayhands/mine/ura\",1)\n",
    "    glob_files(\"./grayhands/okutani/omote\",2)\n",
    "    glob_files(\"./grayhands/okutani/ura\",3)\n",
    "    glob_files(\"./grayhands/tochikubo/omote\",4)\n",
    "    glob_files(\"./grayhands/tochikubo/ura\",5)\n",
    "    glob_files(\"./grayhands/nakamura/omote\",6)\n",
    "    glob_files(\"./grayhands/nakamura/ura\",7)\n",
    "    glob_files(\"./grayhands/gotou/omote\",8)\n",
    "    glob_files(\"./grayhands/gotou/ura\",9)\n",
    "    glob_files(\"./grayhands/mimura/omote\",10)\n",
    "    glob_files(\"./grayhands/mimura/ura\",11)\n",
    "    glob_files(\"./grayhands/arai/omote\",12)\n",
    "    glob_files(\"./grayhands/arai/ura\",13)\n",
    "    glob_files(\"./grayhands/isii/omote\",14)\n",
    "    glob_files(\"./grayhands/isii/ura\",15)\n",
    "    #glob_files(\"./hands/saitouhide/omote\",16)\n",
    "    #glob_files(\"./hands/saitouhide/ura\",17)\n",
    "    #glob_files(\"./hands/saitouryou/omote\",18)\n",
    "    #glob_files(\"./hands/saitouryou/ura\",19)\n",
    "    #glob_files(\"./hands/sakuma/omote\",20)\n",
    "    #glob_files(\"./hands/sakuma/ura\",21)\n",
    "    #glob_files(\"./hands/tanaka/omote\",22)\n",
    "    #glob_files(\"./hands/tanaka/ura\",23)\n",
    "    #glob_files(\"./hands/tokuyama/omote\",24)\n",
    "    #glob_files(\"./hands/tokuyama/ura\",25)\n",
    "    #glob_files(\"./hands/watanabe/omote\",26)\n",
    "    #glob_files(\"./hands/watanabe/ura\",27)\n",
    "    #glob_files(\"./hands/yamaguchi/omote\",28)\n",
    "    #glob_files(\"./hands/yamaguchi/ura\",29)\n",
    "    \n",
    "    \n",
    "    #glob_files(\"./hands/sekine/omote\",30)\n",
    "    #glob_files(\"./hands/sekine/ura\",31)\n",
    "    #glob_files(\"./hands/toriumi/omote\",32)\n",
    "    #glob_files(\"./hands/toriumi/ura\",33)\n",
    "    #glob_files(\"./hands/aizawa/omote\",34)\n",
    "    #glob_files(\"./hands/aizawa/ura\",35)\n",
    "    np.savez(outfile,x=x,y=y)\n",
    "    print(\"保存しました:\"+outfile,len(x))\n",
    "    print(x[0],y[0])\n",
    "    \n",
    "def glob_files(path,label):\n",
    "    files=glob.glob(path+\"/*.jpg\")\n",
    "    random.shuffle(files)\n",
    "    num=0\n",
    "    for f in files:\n",
    "        if num>=max_photo: break\n",
    "        num+=1\n",
    "        \n",
    "        #---------Grayscaleの時のプログラム--------------\n",
    "        img=cv2.imread(f)\n",
    "        img_gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        img=cv2.resize(img_gray,(photo_size,photo_size))\n",
    "        \n",
    "        \n",
    "        img=np.asarray(img)#1つの配列に格納（この場合2つ）\n",
    "        x.append(img)\n",
    "        y.append(label)\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62643ca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pro2のnumpyファイルが正しく保存されているかの確認プログラム\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "#写真データ読み込み\n",
    "photos=np.load('./num16graylight400px.npz')\n",
    "x=photos['x']\n",
    "y=photos['y']\n",
    "#開始インデックス\n",
    "idx=1900\n",
    "#pyplotで出力\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(y[i+idx])\n",
    "    plt.imshow(x[i+idx],cmap='gray')\n",
    "\n",
    "#--------------------画像1枚をピックアップして保存する-----------------------------\n",
    "#plt.imshow(x[0],cmap='gray')\n",
    "#plt.savefig('./extract.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3749c11a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#CNNモデルの構築とCNNモデルを用いた機械学習--(pro3)\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def def_model(in_shape, nb_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,\n",
    "              kernel_size=(3, 3),\n",
    "              activation='relu',\n",
    "              input_shape=in_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def get_model(in_shape, nb_classes):\n",
    "    model = def_model(in_shape, nb_classes)\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=RMSprop(),\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "im_rows = 320 # 変更必要\n",
    "im_cols = 320 # 変更必要\n",
    "im_color = 1\n",
    "in_shape = (im_rows, im_cols, im_color)\n",
    "nb_classes = 16 #変更必要\n",
    "\n",
    "photos = np.load('./num16graylight320px.npz')#変更必要\n",
    "x = photos['x']\n",
    "y = photos['y']\n",
    "\n",
    "x = x.reshape(-1, im_rows, im_cols, im_color)\n",
    "x = x.astype('float32') / 255\n",
    "y = keras.utils.to_categorical(y.astype('int32'), nb_classes)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, train_size=0.9)\n",
    "\n",
    "model = get_model(in_shape, nb_classes)\n",
    "\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=256,#変更必要\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('正解率=', score[1], 'loss=', score[0])\n",
    "\n",
    "\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "fig = plt.figure()\n",
    "#fig.savefig(\"gray128pxbatch32.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "fig = plt.figure()\n",
    "#fig.savefig(\"gray128pxbatch32.png\")\n",
    "plt.show()\n",
    "\n",
    "model.save_weights('./hdf/num16graylight320pixbatch256.hdf5') #変更必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f2e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#他人受入率評価用のプログラム\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def def_model(in_shape, nb_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,\n",
    "              kernel_size=(3, 3),\n",
    "              activation='relu',\n",
    "              input_shape=in_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model(in_shape, nb_classes):\n",
    "    model = def_model(in_shape, nb_classes)\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=RMSprop(),\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#他人受入率用のテスト配列\n",
    "omote=[\"saitouhide/omote\",\"saitouryou/omote\",\n",
    "      \"sakuma/omote\",\"tanaka/omote\",\"tokuyama/omote\",\"watanabe/omote\",\n",
    "      \"yamaguchi/omote\"]\n",
    "ura=[\"saitouhide/ura\",\"saitouryou/ura\",\n",
    "      \"sakuma/ura\",\"tanaka/ura\",\"tokuyama/ura\",\"watanabe/ura\",\n",
    "      \"yamaguchi/ura\"]\n",
    "\n",
    "target_omote=[]\n",
    "target_ura=[]\n",
    "passpercent=[]\n",
    "notpasspercent=[]\n",
    "omotepercent=[]\n",
    "urapercent=[]\n",
    "for k in range(7):#変更必要\n",
    "    for i in range(10):\n",
    "        target_omote.append(\"./graytest/\"+str(omote[k])+\"/\"+str(i)+\".jpg\")#変更必要\n",
    "        target_ura.append(\"./graytest/\"+str(ura[k])+\"/\"+str(i)+\".jpg\")#変更必要\n",
    "\n",
    "im_rows = 64 #変更必要\n",
    "im_cols = 64 #変更必要\n",
    "im_color = 1 #変更必要\n",
    "in_shape = (im_rows, im_cols, im_color)\n",
    "nb_classes = 16 #変更必要\n",
    "#配列の最大値　11月追加\n",
    "max_score = 0.0\n",
    "\n",
    "#他人受入率用のラベル\n",
    "LABELS=[\"江波戸の表\",\"江波戸の裏\",\"奥谷君の表\",\"奥谷君の裏\",\n",
    "       \"栃窪先生の表\",\"栃窪先生の裏\",\"中村君の表\",\"中村君の裏\",\n",
    "       \"後藤さんの表\",\"後藤さんの裏\",\"三村君の表\",\"三村君の裏\",\n",
    "       \"新井さんの表\",\"新井さんの裏\",\"石井さんの表\",\"石井さんの裏\"]\n",
    "\n",
    "model = get_model(in_shape, nb_classes)\n",
    "model.load_weights('./num16graylight64pixbatch128.hdf5')#変更必要\n",
    "\n",
    "#最大値を見つける関数 11月追加\n",
    "def findmaxscore(per):\n",
    "    global max_score\n",
    "    if per!=100.0:\n",
    "        if max_score<=per:\n",
    "            max_score=per \n",
    "\n",
    "def check_photo(path):\n",
    "    img=Image.open(path)\n",
    "    img=img.resize((im_cols,im_rows))\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    x=np.asarray(img)\n",
    "    x=x.reshape(-1,im_rows,im_cols,im_color)\n",
    "    x=x/255\n",
    "    \n",
    "    #予測\n",
    "    pre=model.predict([x])[0]#画像の予測\n",
    "    idx=pre.argmax()\n",
    "    per=(pre[idx]*100)\n",
    "    #per=int(pre[idx]*100)\n",
    "    if per<99.999999 and (\"omote\" in path): #閾値変更箇所\n",
    "        omotepercent.append(per)\n",
    "    elif per<99.999999 and (\"ura\" in path): #閾値変更箇所\n",
    "        urapercent.append(per)\n",
    "    else:\n",
    "        pass\n",
    "    return(idx,per)\n",
    "\n",
    "def check_photo_str(path):\n",
    "    idx,per=check_photo(path)\n",
    "    if per>=99.999999: #閾値変更箇所\n",
    "        print(\"この写真は、\",LABELS[idx],\"です。\")\n",
    "        print(\"可能性は、\",per,\"%です。\")\n",
    "        passpercent.append(per)\n",
    "        #配列の最大値を見つける　11月追加\n",
    "        findmaxscore(per)\n",
    "    else:\n",
    "        print('\\033[31m'+\"可能性が\",per,\"%なので認証できません。\"+'\\033[31m')\n",
    "        print(\"認証の結果は\",LABELS[idx],\"でした。\")\n",
    "        notpasspercent.append(per)\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    number=[9,19,29,39,49,59,69,79,89,99,109,119,129,139,149]\n",
    "    for i in range(70):\n",
    "        print(\"\\nここからは\"+str(i)+\"番目の写真です\")\n",
    "        check_photo_str(target_omote[i])\n",
    "        for l in range(15):\n",
    "            if i==number[l]:\n",
    "                print(\"================================================\")\n",
    "                print(\"テスト対象の人が変わります\")\n",
    "                print(\"================================================\")\n",
    "    for i in range(70):\n",
    "        print(\"\\nここからは\"+str(i)+\"番目の写真です\")\n",
    "        check_photo_str(target_ura[i])\n",
    "        for l in range(15):\n",
    "            if i==number[l]:\n",
    "                print(\"================================================\")\n",
    "                print(\"テスト対象の人が変わります\")\n",
    "                print(\"================================================\")\n",
    "   \n",
    "    print(passpercent)\n",
    "    print(notpasspercent)\n",
    "    print(\"閾値以上で識別したテスト数\"+str(len(passpercent)))\n",
    "    print(\"閾値未満で識別したテスト数\"+str(len(notpasspercent)))\n",
    "    print(\"表の手だけで閾値未満で識別したテスト数\"+str(len(omotepercent)))\n",
    "    print(\"裏の手だけで閾値未満で識別したテスト数\"+str(len(urapercent)))\n",
    "    totalpass=len(passpercent)/140\n",
    "    totalnotpass=len(notpasspercent)/140\n",
    "    omotenotpass=len(omotepercent)/70\n",
    "    omotepass=(70-len(omotepercent))/70\n",
    "    uranotpass=len(urapercent)/70\n",
    "    urapass=(70-len(urapercent))/70\n",
    "    print(\"================================================\")\n",
    "    print(\"未学習の手を閾値未満で識別した割合\"+str(round(totalnotpass*100))+\"%\")\n",
    "    print(\"未学習の手を閾値以上で識別した割合\"+str(round(totalpass*100))+\"%\")\n",
    "    print(\"表の手だけで未学習の手を閾値未満で識別した割合\"+str(round(omotenotpass*100))+\"%\")\n",
    "    print(\"表の手だけで未学習の手を閾値以上で識別した割合\"+str(round(omotepass*100))+\"%\")\n",
    "    print(\"裏の手だけで未学習の手を閾値未満で識別した割合\"+str(round(uranotpass*100))+\"%\")\n",
    "    print(\"裏の手だけで未学習の手を閾値以上で識別した割合\"+str(round(urapass*100))+\"%\")\n",
    "    print(\"閾値以上の最大値は\"+str(max_score)) #11月追加\n",
    "    print(\"閾値以上の最小値は\"+str(min(passpercent))) #11月追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f11ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#本人受入率評価用のプログラム\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def def_model(in_shape, nb_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,\n",
    "              kernel_size=(3, 3),\n",
    "              activation='relu',\n",
    "              input_shape=in_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model(in_shape, nb_classes):\n",
    "    model = def_model(in_shape, nb_classes)\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=RMSprop(),\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#本人受入率用のテスト配列\n",
    "omote=[\"mine/omote\",\"okutani/omote\",\"tochikubo/omote\",\n",
    "       \"nakamura/omote\",\"gotou/omote\",\"mimura/omote\",\n",
    "       \"arai/omote\",\"isii/omote\"]\n",
    "ura=[\"mine/ura\",\"okutani/ura\",\"tochikubo/ura\",\n",
    "       \"nakamura/ura\",\"gotou/ura\",\"mimura/ura\",\n",
    "       \"arai/ura\",\"isii/ura\"]\n",
    "alart=0\n",
    "target_omote=[]\n",
    "target_ura=[]\n",
    "passpercent=[]\n",
    "notpasspercent=[]\n",
    "omotepercent=[]\n",
    "urapercent=[]\n",
    "#配列の最大値　11月追加\n",
    "max_score = 0.0\n",
    "\n",
    "for k in range(8):#変更必要\n",
    "    for i in range(10):\n",
    "        target_omote.append(\"./graytest/\"+str(omote[k])+\"/\"+str(i)+\".jpg\")#変更必要\n",
    "        target_ura.append(\"./graytest/\"+str(ura[k])+\"/\"+str(i)+\".jpg\")#変更必要\n",
    "\n",
    "im_rows = 64 #変更必要\n",
    "im_cols = 64 #変更必要\n",
    "im_color = 1 #変更必要\n",
    "in_shape = (im_rows, im_cols, im_color)\n",
    "nb_classes = 16 #変更必要\n",
    "#配列の最大値\n",
    "max_score = 0.0\n",
    "\n",
    "#ラベル\n",
    "LABELS=[\"江波戸の表\",\"江波戸の裏\",\"奥谷君の表\",\"奥谷君の裏\",\n",
    "       \"栃窪先生の表\",\"栃窪先生の裏\",\"中村君の表\",\"中村君の裏\",\n",
    "       \"後藤さんの表\",\"後藤さんの裏\",\"三村君の表\",\"三村君の裏\",\n",
    "       \"新井さんの表\",\"新井さんの裏\",\"石井さんの表\",\"石井さんの裏\"]\n",
    "\n",
    "model = get_model(in_shape, nb_classes)\n",
    "model.load_weights('./num16graylight64pixbatch128.hdf5')#変更必要\n",
    "\n",
    "def findmaxscore(per):\n",
    "    global max_score\n",
    "    if per!=100.0:\n",
    "        if max_score<=per:\n",
    "            max_score=per\n",
    "            \n",
    "def check_photo(path):\n",
    "    img=Image.open(path)\n",
    "    img=img.resize((im_cols,im_rows))\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    x=np.asarray(img)\n",
    "    x=x.reshape(-1,im_rows,im_cols,im_color)\n",
    "    x=x/255\n",
    "    \n",
    "    #予測\n",
    "    pre=model.predict([x])[0]#画像の予測\n",
    "    idx=pre.argmax()\n",
    "    per=(pre[idx]*100)\n",
    "    #per=int(pre[idx]*100)\n",
    "    if per<99.999999 and (\"omote\" in path): #閾値変更箇所\n",
    "        omotepercent.append(per)\n",
    "    elif per<99.999999 and (\"ura\" in path): #閾値変更箇所\n",
    "        urapercent.append(per)\n",
    "    else:\n",
    "        pass\n",
    "    return(idx,per)\n",
    "\n",
    "def check_photo_str(path,i):\n",
    "    idx,per=check_photo(path)\n",
    "    if per>=99.999999: #閾値変更箇所\n",
    "        print(\"この写真は、\",LABELS[idx],\"です。\")\n",
    "        #閾値以上なのに識別を間違えているときの処理\n",
    "        amari=i/10\n",
    "        if \"表\" in LABELS[idx]==\"表\" in LABELS[math.floor(amari)]:\n",
    "            if LABELS[idx]!=LABELS[math.floor(amari)]:\n",
    "                alart=1\n",
    "                print('識別エラーが起きています'+'\\033[31m')\n",
    "        if \"裏\" in LABELS[idx]==\"裏\" in LABELS[math.floor(amari)]:\n",
    "            if LABELS[idx]!=LABELS[math.floor(amari)]:\n",
    "                alart=1\n",
    "                print('識別エラーが起きています'+'\\033[31m')\n",
    "        #-------------------------------------------\n",
    "        print(\"可能性は、\",per,\"%です。\")\n",
    "        passpercent.append(per)\n",
    "        #配列の最大値を見つける\n",
    "        findmaxscore(per)\n",
    "    else:\n",
    "        print('\\033[31m'+\"可能性が\",per,\"%なので認証できません。\"+'\\033[31m')\n",
    "        print(\"認証の結果は\",LABELS[idx],\"でした。\")\n",
    "        notpasspercent.append(per)\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    number=[9,19,29,39,49,59,69,79,89,99,109,119,129,139,149]\n",
    "    for i in range(80):\n",
    "        print(\"\\nここからは\"+str(i)+\"番目の写真です\")\n",
    "        check_photo_str(target_omote[i],i)\n",
    "        for l in range(15):\n",
    "            if i==number[l]:\n",
    "                print(\"================================================\")\n",
    "                print(\"テスト対象の人が変わります\")\n",
    "                print(\"================================================\")\n",
    "    for i in range(80):\n",
    "        print(\"\\nここからは\"+str(i)+\"番目の写真です\")\n",
    "        check_photo_str(target_ura[i],i)\n",
    "        for l in range(15):\n",
    "            if i==number[l]:\n",
    "                print(\"================================================\")\n",
    "                print(\"テスト対象の人が変わります\")\n",
    "                print(\"================================================\")\n",
    "   \n",
    "    print(passpercent)\n",
    "    print(notpasspercent)\n",
    "    print(\"閾値以上で識別したテスト数\"+str(len(passpercent)))\n",
    "    print(\"閾値未満で識別したテスト数\"+str(len(notpasspercent)))\n",
    "    print(\"表の手だけで閾値未満で識別したテスト数\"+str(len(omotepercent)))\n",
    "    print(\"裏の手だけで閾値未満で識別したテスト数\"+str(len(urapercent)))\n",
    "    totalpass=len(passpercent)/160\n",
    "    totalnotpass=len(notpasspercent)/160\n",
    "    omotenotpass=len(omotepercent)/80\n",
    "    omotepass=(80-len(omotepercent))/80\n",
    "    uranotpass=len(urapercent)/80\n",
    "    urapass=(80-len(urapercent))/80\n",
    "    print(\"================================================\")\n",
    "    print(\"未学習の手を閾値未満で識別した割合\"+str(round(totalnotpass*100))+\"%\")\n",
    "    print(\"未学習の手を閾値以上で識別した割合\"+str(round(totalpass*100))+\"%\")\n",
    "    print(\"表の手だけで未学習の手を閾値未満で識別した割合\"+str(round(omotenotpass*100))+\"%\")\n",
    "    print(\"表の手だけで未学習の手を閾値以上で識別した割合\"+str(round(omotepass*100))+\"%\")\n",
    "    print(\"裏の手だけで未学習の手を閾値未満で識別した割合\"+str(round(uranotpass*100))+\"%\")\n",
    "    print(\"裏の手だけで未学習の手を閾値以上で識別した割合\"+str(round(urapass*100))+\"%\")\n",
    "    print(\"閾値以上の最大値は\"+str(max_score)) #11月追加\n",
    "    print(\"閾値以上の最小値は\"+str(min(passpercent))) #11月追加\n",
    "    #閾値以上なのに識別を間違えているときのエラーを出力する\n",
    "    if alart==1:\n",
    "        print('識別エラーが起きています'+'\\033[31m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ec4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef945c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
