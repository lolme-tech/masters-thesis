{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524abb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#エッジ用のnumpy保存プログラム\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os,glob,random\n",
    "\n",
    "outfile=\"./num16karnel3light128px.npz\"#変更必要\n",
    "max_photo=40000\n",
    "photo_size=128#変更必要\n",
    "x=[]\n",
    "y=[]\n",
    "laplace5=[[-1,-3,-4,-3,-1],\n",
    "         [-3,0,6,0,-3],\n",
    "         [-4,6,20,6,-4],\n",
    "         [-3,0,6,0,-3],\n",
    "         [-1,-3,-4,-3,-1]]\n",
    "laplace3=[[1,1,1],\n",
    "         [1,-8,1],\n",
    "         [1,1,1]]\n",
    "def main():\n",
    "    glob_files(\"./grayhands/mine/omote\",0)\n",
    "    glob_files(\"./grayhands/mine/ura\",1)\n",
    "    glob_files(\"./grayhands/okutani/omote\",2)\n",
    "    glob_files(\"./grayhands/okutani/ura\",3)\n",
    "    glob_files(\"./grayhands/tochikubo/omote\",4)\n",
    "    glob_files(\"./grayhands/tochikubo/ura\",5)\n",
    "    glob_files(\"./grayhands/nakamura/omote\",6)\n",
    "    glob_files(\"./grayhands/nakamura/ura\",7)\n",
    "    glob_files(\"./grayhands/gotou/omote\",8)\n",
    "    glob_files(\"./grayhands/gotou/ura\",9)\n",
    "    glob_files(\"./grayhands/mimura/omote\",10)\n",
    "    glob_files(\"./grayhands/mimura/ura\",11)\n",
    "    glob_files(\"./grayhands/arai/omote\",12)\n",
    "    glob_files(\"./grayhands/arai/ura\",13)\n",
    "    glob_files(\"./grayhands/isii/omote\",14)\n",
    "    glob_files(\"./grayhands/isii/ura\",15)\n",
    "    #glob_files(\"./hands/saitouhide/omote\",16)\n",
    "    #glob_files(\"./hands/saitouhide/ura\",17)\n",
    "    #glob_files(\"./hands/saitouryou/omote\",18)\n",
    "    #glob_files(\"./hands/saitouryou/ura\",19)\n",
    "    #glob_files(\"./hands/sakuma/omote\",20)\n",
    "    #glob_files(\"./hands/sakuma/ura\",21)\n",
    "    #glob_files(\"./hands/tanaka/omote\",22)\n",
    "    #glob_files(\"./hands/tanaka/ura\",23)\n",
    "    #glob_files(\"./hands/tokuyama/omote\",24)\n",
    "    #glob_files(\"./hands/tokuyama/ura\",25)\n",
    "    #glob_files(\"./hands/watanabe/omote\",26)\n",
    "    #glob_files(\"./hands/watanabe/ura\",27)\n",
    "    #glob_files(\"./hands/yamaguchi/omote\",28)\n",
    "    #glob_files(\"./hands/yamaguchi/ura\",29)\n",
    "\n",
    "    np.savez(outfile,x=x,y=y)\n",
    "    print(\"保存しました:\"+outfile,len(x))\n",
    "    print(x[0],y[0])\n",
    "    \n",
    "def glob_files(path,label):\n",
    "    files=glob.glob(path+\"/*.jpg\")\n",
    "    random.shuffle(files)\n",
    "    num=0\n",
    "    for f in files:\n",
    "        if num>=max_photo: break\n",
    "        num+=1\n",
    "        \n",
    "        #---------edgesの時のプログラム--------------\n",
    "        img=cv2.imread(f)\n",
    "        img_gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        karnel=np.array(laplace3,np.float64)#変更必要\n",
    "        edges=cv2.filter2D(img_gray,-1,karnel)\n",
    "        edges=cv2.resize(edges,(photo_size,photo_size))\n",
    "        \n",
    "        \n",
    "        edges=np.asarray(edges)#1つの配列に格納（この場合2つ）\n",
    "        x.append(edges)\n",
    "        y.append(label)\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24932b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#エッジファイルの中身を確認するプログラム\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "#写真データ読み込み\n",
    "photos=np.load('./num16edges5light256.npz')#変更必要\n",
    "x=photos['x']\n",
    "y=photos['y']\n",
    "#開始インデックス\n",
    "idx=1900\n",
    "#pyplotで出力\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.axis(\"off\")\n",
    "print(x[0])\n",
    "print(x[1])\n",
    "'''\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.axis(\"off\")\n",
    "    #グレイスケール画像を読み込むときは、plt.grayが必要\n",
    "    #plt.gray\n",
    "    plt.title(y[i+idx])\n",
    "    plt.imshow(x[i+idx],cmap='gray')\n",
    "    #plt.savefig('./extract.jpg')\n",
    "'''\n",
    "#--------------------画像1枚をピックアップして保存する-----------------------------\n",
    "plt.imshow(x[0])\n",
    "#plt.imshow(x[1],cmap='gray')\n",
    "plt.savefig('./edges128.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e3bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#エッジ検出を用いた機械学習\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def def_model(in_shape, nb_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,\n",
    "              kernel_size=(3, 3),\n",
    "              activation='relu',\n",
    "              input_shape=in_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def get_model(in_shape, nb_classes):\n",
    "    model = def_model(in_shape, nb_classes)\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=RMSprop(),\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "im_rows = 128 # 変更必要\n",
    "im_cols = 128 # 変更必要\n",
    "im_color = 1\n",
    "in_shape = (im_rows, im_cols, im_color)\n",
    "nb_classes = 16 #変更必要\n",
    "\n",
    "photos = np.load('./num16edges5light256.npz')#変更必要\n",
    "x = photos['x']\n",
    "y = photos['y']\n",
    "\n",
    "x = x.reshape(-1, im_rows, im_cols, im_color)\n",
    "x = x.astype('float32') / 255\n",
    "y = keras.utils.to_categorical(y.astype('int32'), nb_classes)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, train_size=0.8)\n",
    "\n",
    "model = get_model(in_shape, nb_classes)\n",
    "\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('正解率=', score[1], 'loss=', score[0])\n",
    "\n",
    "\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "model.save_weights('./hdf/num16karnel3light128pix.hdf5') #変更必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0981e05",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-76d64f04b108>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#エッジ検出を用いた機械学習\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mforward_compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\v2\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mforward_compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\compat\\v2\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[0m_current_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m   _current_module.__path__ = (\n\u001b[0;32m    329\u001b[0m       [_module_util.get_parent_dir(summary)] + _current_module.__path__)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\summary\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# If the V1 summary API is accessible, load and re-export it here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\summary\\v1.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_histogram_summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_image_summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpr_curve\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pr_curve_summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_scalar_summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_text_summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\plugins\\pr_curve\\summary.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpr_curve\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mpath_stats\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#エッジ検出を用いた機械学習\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def def_model(in_shape, nb_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,\n",
    "              kernel_size=(3, 3),\n",
    "              activation='relu',\n",
    "              input_shape=in_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model(in_shape, nb_classes):\n",
    "    model = def_model(in_shape, nb_classes)\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=RMSprop(),\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "#他人受入率用のテスト配列\n",
    "omote=[\"saitouhide/omote\",\"saitouryou/omote\",\n",
    "      \"sakuma/omote\",\"tanaka/omote\",\"tokuyama/omote\",\"watanabe/omote\",\n",
    "      \"yamaguchi/omote\"]\n",
    "ura=[\"saitouhide/ura\",\"saitouryou/ura\",\n",
    "      \"sakuma/ura\",\"tanaka/ura\",\"tokuyama/ura\",\"watanabe/ura\",\n",
    "      \"yamaguchi/ura\"]\n",
    "\n",
    "target_omote=[]\n",
    "target_ura=[]\n",
    "laplace5=[[-1,-3,-4,-3,-1],\n",
    "         [-3,0,6,0,-3],\n",
    "         [-4,6,20,6,-4],\n",
    "         [-3,0,6,0,-3],\n",
    "         [-1,-3,-4,-3,-1]]\n",
    "laplace3=[[1,1,1],\n",
    "         [1,-8,1],\n",
    "         [1,1,1]]\n",
    "passpercent=[]\n",
    "notpasspercent=[]\n",
    "omotepercent=[]\n",
    "urapercent=[]\n",
    "for k in range(7):#変更必要\n",
    "    for i in range(10):\n",
    "        target_omote.append(\"./graytest/\"+str(omote[k])+\"/\"+str(i)+\".jpg\")#変更必要\n",
    "        target_ura.append(\"./graytest/\"+str(ura[k])+\"/\"+str(i)+\".jpg\")#変更必要\n",
    "\n",
    "\n",
    "im_rows = 128 #変更必要\n",
    "im_cols = 128 #変更必要\n",
    "im_color = 1 #変更必要\n",
    "in_shape = (im_rows, im_cols, im_color)\n",
    "nb_classes = 16 #変更必要\n",
    "\n",
    "#他人受入率用のラベル\n",
    "\n",
    "LABELS=[\"江波戸の表\",\"江波戸の裏\",\"奥谷君の表\",\"奥谷君の裏\",\n",
    "       \"栃窪先生の表\",\"栃窪先生の裏\",\"中村君の表\",\"中村君の裏\",\n",
    "       \"後藤さんの表\",\"後藤さんの裏\",\"三村君の表\",\"三村君の裏\",\n",
    "       \"新井さんの表\",\"新井さんの裏\",\"石井さんの表\",\"石井さんの裏\"]\n",
    "\n",
    "model = get_model(in_shape, nb_classes)\n",
    "model.load_weights('./hdf/num16karnel3light128pix.hdf5')#変更必要\n",
    "\n",
    "def check_photo(path):\n",
    "    img=cv2.imread(path)\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    karnel=np.array(laplace3,np.float64)\n",
    "    #img=Image.open(path)\n",
    "    img=cv2.filter2D(img,-1,karnel)\n",
    "    img=cv2.resize(img,(im_rows,im_cols))\n",
    "    plt.imshow(img,cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "    x=np.asarray(img)\n",
    "    x=x.reshape(-1,im_rows,im_cols,im_color)\n",
    "    x=x/255\n",
    "    \n",
    "    #予測\n",
    "    pre=model.predict([x])[0]#画像の予測\n",
    "    idx=pre.argmax()\n",
    "    #per=(pre[idx]*100)\n",
    "    per=int(pre[idx]*100)\n",
    "    if per<99 and (\"omote\" in path):\n",
    "        omotepercent.append(per)\n",
    "    elif per<99 and (\"ura\" in path):\n",
    "        urapercent.append(per)\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    return(idx,per)\n",
    "\n",
    "def check_photo_str(path):\n",
    "    idx,per=check_photo(path)\n",
    "    if per>=99:\n",
    "        print(\"この写真は、\",LABELS[idx],\"です。\")\n",
    "        print(\"可能性は、\",per,\"%です。\")\n",
    "        passpercent.append(per)\n",
    "    else:\n",
    "        print('\\033[31m'+\"可能性が\",per,\"%なので認証できません。\"+'\\033[31m')\n",
    "        print(\"認証の結果は\",LABELS[idx],\"でした。\")\n",
    "        notpasspercent.append(per)\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    number=[9,19,29,39,49,59,69,79,89,99,109,119,129,139,149]\n",
    "    for i in range(70):\n",
    "        print(\"\\nここからは\"+str(i)+\"番目の写真です\")\n",
    "        check_photo_str(target_omote[i])\n",
    "        for l in range(15):\n",
    "            if i==number[l]:\n",
    "                print(\"================================================\")\n",
    "                print(\"テスト対象の人が変わります\")\n",
    "                print(\"================================================\")\n",
    "    for i in range(70):\n",
    "        print(\"\\nここからは\"+str(i)+\"番目の写真です\")\n",
    "        check_photo_str(target_ura[i])\n",
    "        for l in range(15):\n",
    "            if i==number[l]:\n",
    "                print(\"================================================\")\n",
    "                print(\"テスト対象の人が変わります\")\n",
    "                print(\"================================================\")\n",
    "    print(passpercent)\n",
    "    print(notpasspercent)\n",
    "    print(\"閾値以上で識別したテスト数\"+str(len(passpercent)))\n",
    "    print(\"閾値未満で識別したテスト数\"+str(len(notpasspercent)))\n",
    "    print(\"表の手だけで閾値未満で識別したテスト数\"+str(len(omotepercent)))\n",
    "    print(\"裏の手だけで閾値未満で識別したテスト数\"+str(len(urapercent)))\n",
    "    totalpass=len(passpercent)/140\n",
    "    totalnotpass=len(notpasspercent)/140\n",
    "    omotenotpass=len(omotepercent)/70\n",
    "    omotepass=(70-len(omotepercent))/70\n",
    "    uranotpass=len(urapercent)/70\n",
    "    urapass=(70-len(urapercent))/70\n",
    "    print(\"================================================\")\n",
    "    print(\"未学習の手を閾値以上で識別した割合\"+str(round(totalpass*100))+\"%\")\n",
    "    print(\"未学習の手を閾値未満で識別した割合\"+str(round(totalnotpass*100))+\"%\")\n",
    "    print(\"表の手だけで未学習の手を閾値以上で識別した割合\"+str(round(omotepass*100))+\"%\")\n",
    "    print(\"表の手だけで未学習の手を閾値未満で識別した割合\"+str(round(omotenotpass*100))+\"%\")\n",
    "    print(\"裏の手だけで未学習の手を閾値以上で識別した割合\"+str(round(urapass*100))+\"%\")\n",
    "    print(\"裏の手だけで未学習の手を閾値未満で識別した割合\"+str(round(uranotpass*100))+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996343b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#エッジ検出を用いた機械学習\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def def_model(in_shape, nb_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,\n",
    "              kernel_size=(3, 3),\n",
    "              activation='relu',\n",
    "              input_shape=in_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model(in_shape, nb_classes):\n",
    "    model = def_model(in_shape, nb_classes)\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=RMSprop(),\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "#本人受入率用のテスト配列\n",
    "\n",
    "omote=[\"mine/omote\",\"okutani/omote\",\"tochikubo/omote\",\n",
    "       \"nakamura/omote\",\"gotou/omote\",\"mimura/omote\",\n",
    "       \"arai/omote\",\"isii/omote\"]\n",
    "ura=[\"mine/ura\",\"okutani/ura\",\"tochikubo/ura\",\n",
    "       \"nakamura/ura\",\"gotou/ura\",\"mimura/ura\",\n",
    "       \"arai/ura\",\"isii/ura\"]\n",
    "\n",
    "target_omote=[]\n",
    "target_ura=[]\n",
    "laplace5=[[-1,-3,-4,-3,-1],\n",
    "         [-3,0,6,0,-3],\n",
    "         [-4,6,20,6,-4],\n",
    "         [-3,0,6,0,-3],\n",
    "         [-1,-3,-4,-3,-1]]\n",
    "laplace3=[[1,1,1],\n",
    "         [1,-8,1],\n",
    "         [1,1,1]]\n",
    "passpercent=[]\n",
    "notpasspercent=[]\n",
    "omotepercent=[]\n",
    "urapercent=[]\n",
    "for k in range(7):#変更必要\n",
    "    for i in range(10):\n",
    "        target_omote.append(\"./graytest/\"+str(omote[k])+\"/\"+str(i)+\".jpg\")#変更必要\n",
    "        target_ura.append(\"./graytest/\"+str(ura[k])+\"/\"+str(i)+\".jpg\")#変更必要\n",
    "\n",
    "\n",
    "im_rows = 128 #変更必要\n",
    "im_cols = 128 #変更必要\n",
    "im_color = 1 #変更必要\n",
    "in_shape = (im_rows, im_cols, im_color)\n",
    "nb_classes = 16 #変更必要\n",
    "\n",
    "#ラベル\n",
    "\n",
    "LABELS=[\"江波戸の表\",\"江波戸の裏\",\"奥谷君の表\",\"奥谷君の裏\",\n",
    "       \"栃窪先生の表\",\"栃窪先生の裏\",\"中村君の表\",\"中村君の裏\",\n",
    "       \"後藤さんの表\",\"後藤さんの裏\",\"三村君の表\",\"三村君の裏\",\n",
    "       \"新井さんの表\",\"新井さんの裏\",\"石井さんの表\",\"石井さんの裏\"]\n",
    "\n",
    "model = get_model(in_shape, nb_classes)\n",
    "model.load_weights('./hdf/num16karnel3light128pix.hdf5')#変更必要\n",
    "\n",
    "def check_photo(path):\n",
    "    img=cv2.imread(path)\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    karnel=np.array(laplace3,np.float64)\n",
    "    #img=Image.open(path)\n",
    "    img=cv2.filter2D(img,-1,karnel)\n",
    "    img=cv2.resize(img,(im_rows,im_cols))\n",
    "    plt.imshow(img,cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "    x=np.asarray(img)\n",
    "    x=x.reshape(-1,im_rows,im_cols,im_color)\n",
    "    x=x/255\n",
    "    \n",
    "    #予測\n",
    "    pre=model.predict([x])[0]#画像の予測\n",
    "    idx=pre.argmax()\n",
    "    #per=(pre[idx]*100)\n",
    "    per=int(pre[idx]*100)\n",
    "    if per<99 and (\"omote\" in path):\n",
    "        omotepercent.append(per)\n",
    "    elif per<99 and (\"ura\" in path):\n",
    "        urapercent.append(per)\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    return(idx,per)\n",
    "\n",
    "def check_photo_str(path):\n",
    "    idx,per=check_photo(path)\n",
    "    if per>=99:\n",
    "        print(\"この写真は、\",LABELS[idx],\"です。\")\n",
    "        print(\"可能性は、\",per,\"%です。\")\n",
    "        passpercent.append(per)\n",
    "    else:\n",
    "        print('\\033[31m'+\"可能性が\",per,\"%なので認証できません。\"+'\\033[31m')\n",
    "        print(\"認証の結果は\",LABELS[idx],\"でした。\")\n",
    "        notpasspercent.append(per)\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    number=[9,19,29,39,49,59,69,79,89,99,109,119,129,139,149]\n",
    "    for i in range(70):\n",
    "        print(\"\\nここからは\"+str(i)+\"番目の写真です\")\n",
    "        check_photo_str(target_omote[i])\n",
    "        for l in range(15):\n",
    "            if i==number[l]:\n",
    "                print(\"================================================\")\n",
    "                print(\"テスト対象の人が変わります\")\n",
    "                print(\"================================================\")\n",
    "    for i in range(70):\n",
    "        print(\"\\nここからは\"+str(i)+\"番目の写真です\")\n",
    "        check_photo_str(target_ura[i])\n",
    "        for l in range(15):\n",
    "            if i==number[l]:\n",
    "                print(\"================================================\")\n",
    "                print(\"テスト対象の人が変わります\")\n",
    "                print(\"================================================\")\n",
    "    print(passpercent)\n",
    "    print(notpasspercent)\n",
    "    print(\"閾値以上で識別したテスト数\"+str(len(passpercent)))\n",
    "    print(\"閾値未満で識別したテスト数\"+str(len(notpasspercent)))\n",
    "    print(\"表の手だけで閾値未満で識別したテスト数\"+str(len(omotepercent)))\n",
    "    print(\"裏の手だけで閾値未満で識別したテスト数\"+str(len(urapercent)))\n",
    "    totalpass=len(passpercent)/140\n",
    "    totalnotpass=len(notpasspercent)/140\n",
    "    omotenotpass=len(omotepercent)/70\n",
    "    omotepass=(70-len(omotepercent))/70\n",
    "    uranotpass=len(urapercent)/70\n",
    "    urapass=(70-len(urapercent))/70\n",
    "    print(\"================================================\")\n",
    "    print(\"未学習の手を閾値以上で識別した割合\"+str(round(totalpass*100))+\"%\")\n",
    "    print(\"未学習の手を閾値未満で識別した割合\"+str(round(totalnotpass*100))+\"%\")\n",
    "    print(\"表の手だけで未学習の手を閾値以上で識別した割合\"+str(round(omotepass*100))+\"%\")\n",
    "    print(\"表の手だけで未学習の手を閾値未満で識別した割合\"+str(round(omotenotpass*100))+\"%\")\n",
    "    print(\"裏の手だけで未学習の手を閾値以上で識別した割合\"+str(round(urapass*100))+\"%\")\n",
    "    print(\"裏の手だけで未学習の手を閾値未満で識別した割合\"+str(round(uranotpass*100))+\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
