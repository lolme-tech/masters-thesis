{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524abb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#エッジ用のnumpy保存プログラム\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os,glob,random\n",
    "\n",
    "outfile=\"./num16edges5light256.npz\"#変更必要\n",
    "max_photo=40000\n",
    "photo_size=256#変更必要\n",
    "x=[]\n",
    "y=[]\n",
    "laplace5=[[-1,-3,-4,-3,-1],\n",
    "         [-3,0,6,0,-3],\n",
    "         [-4,6,20,6,-4],\n",
    "         [-3,0,6,0,-3],\n",
    "         [-1,-3,-4,-3,-1]]\n",
    "laplace3=[[1,1,1],\n",
    "         [1,-8,1],\n",
    "         [1,1,1]]\n",
    "def main():\n",
    "    glob_files(\"./grayhands/mine/omote\",0)\n",
    "    glob_files(\"./grayhands/mine/ura\",1)\n",
    "    glob_files(\"./grayhands/okutani/omote\",2)\n",
    "    glob_files(\"./grayhands/okutani/ura\",3)\n",
    "    glob_files(\"./grayhands/tochikubo/omote\",4)\n",
    "    glob_files(\"./grayhands/tochikubo/ura\",5)\n",
    "    glob_files(\"./grayhands/nakamura/omote\",6)\n",
    "    glob_files(\"./grayhands/nakamura/ura\",7)\n",
    "    glob_files(\"./grayhands/gotou/omote\",8)\n",
    "    glob_files(\"./grayhands/gotou/ura\",9)\n",
    "    glob_files(\"./grayhands/mimura/omote\",10)\n",
    "    glob_files(\"./grayhands/mimura/ura\",11)\n",
    "    glob_files(\"./grayhands/arai/omote\",12)\n",
    "    glob_files(\"./grayhands/arai/ura\",13)\n",
    "    glob_files(\"./grayhands/isii/omote\",14)\n",
    "    glob_files(\"./grayhands/isii/ura\",15)\n",
    "    #glob_files(\"./hands/saitouhide/omote\",16)\n",
    "    #glob_files(\"./hands/saitouhide/ura\",17)\n",
    "    #glob_files(\"./hands/saitouryou/omote\",18)\n",
    "    #glob_files(\"./hands/saitouryou/ura\",19)\n",
    "    #glob_files(\"./hands/sakuma/omote\",20)\n",
    "    #glob_files(\"./hands/sakuma/ura\",21)\n",
    "    #glob_files(\"./hands/tanaka/omote\",22)\n",
    "    #glob_files(\"./hands/tanaka/ura\",23)\n",
    "    #glob_files(\"./hands/tokuyama/omote\",24)\n",
    "    #glob_files(\"./hands/tokuyama/ura\",25)\n",
    "    #glob_files(\"./hands/watanabe/omote\",26)\n",
    "    #glob_files(\"./hands/watanabe/ura\",27)\n",
    "    #glob_files(\"./hands/yamaguchi/omote\",28)\n",
    "    #glob_files(\"./hands/yamaguchi/ura\",29)\n",
    "\n",
    "    np.savez(outfile,x=x,y=y)\n",
    "    print(\"保存しました:\"+outfile,len(x))\n",
    "    print(x[0],y[0])\n",
    "    \n",
    "def glob_files(path,label):\n",
    "    files=glob.glob(path+\"/*.jpg\")\n",
    "    random.shuffle(files)\n",
    "    num=0\n",
    "    for f in files:\n",
    "        if num>=max_photo: break\n",
    "        num+=1\n",
    "        \n",
    "        #---------edgesの時のプログラム--------------\n",
    "        img=cv2.imread(f)\n",
    "        img_gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        karnel=np.array(laplace5,np.float64)#変更必要\n",
    "        edges=cv2.filter2D(img_gray,-1,karnel)\n",
    "        edges=cv2.resize(edges,(photo_size,photo_size))\n",
    "        \n",
    "        \n",
    "        edges=np.asarray(edges)#1つの配列に格納（この場合2つ）\n",
    "        x.append(edges)\n",
    "        y.append(label)\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24932b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#エッジファイルの中身を確認するプログラム\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "#写真データ読み込み\n",
    "photos=np.load('./num16edges5light256.npz')#変更必要\n",
    "x=photos['x']\n",
    "y=photos['y']\n",
    "#開始インデックス\n",
    "idx=1900\n",
    "#pyplotで出力\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.axis(\"off\")\n",
    "print(x[0])\n",
    "print(x[1])\n",
    "'''\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.axis(\"off\")\n",
    "    #グレイスケール画像を読み込むときは、plt.grayが必要\n",
    "    #plt.gray\n",
    "    plt.title(y[i+idx])\n",
    "    plt.imshow(x[i+idx],cmap='gray')\n",
    "    #plt.savefig('./extract.jpg')\n",
    "'''\n",
    "#--------------------画像1枚をピックアップして保存する-----------------------------\n",
    "plt.imshow(x[0])\n",
    "#plt.imshow(x[1],cmap='gray')\n",
    "plt.savefig('./edges128.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e3bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#エッジ検出を用いた機械学習\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def def_model(in_shape, nb_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,\n",
    "              kernel_size=(3, 3),\n",
    "              activation='relu',\n",
    "              input_shape=in_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def get_model(in_shape, nb_classes):\n",
    "    model = def_model(in_shape, nb_classes)\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=RMSprop(),\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "im_rows = 256 # 変更必要\n",
    "im_cols = 256 # 変更必要\n",
    "im_color = 1\n",
    "in_shape = (im_rows, im_cols, im_color)\n",
    "nb_classes = 16 #変更必要\n",
    "\n",
    "photos = np.load('./num16edges5light256.npz')#変更必要\n",
    "x = photos['x']\n",
    "y = photos['y']\n",
    "\n",
    "x = x.reshape(-1, im_rows, im_cols, im_color)\n",
    "x = x.astype('float32') / 255\n",
    "y = keras.utils.to_categorical(y.astype('int32'), nb_classes)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, train_size=0.8)\n",
    "\n",
    "model = get_model(in_shape, nb_classes)\n",
    "\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('正解率=', score[1], 'loss=', score[0])\n",
    "\n",
    "\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "model.save_weights('./hdf/num16edges5light256pix.hdf5') #変更必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0981e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#エッジ検出を用いた機械学習\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def def_model(in_shape, nb_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,\n",
    "              kernel_size=(3, 3),\n",
    "              activation='relu',\n",
    "              input_shape=in_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model(in_shape, nb_classes):\n",
    "    model = def_model(in_shape, nb_classes)\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=RMSprop(),\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#本人受入率用のテスト配列\n",
    "\n",
    "omote=[\"mine/omote\",\"okutani/omote\",\"tochikubo/omote\",\n",
    "       \"nakamura/omote\",\"gotou/omote\",\"mimura/omote\",\n",
    "       \"arai/omote\",\"isii/omote\"]\n",
    "ura=[\"mine/ura\",\"okutani/ura\",\"tochikubo/ura\",\n",
    "       \"nakamura/ura\",\"gotou/ura\",\"mimura/ura\",\n",
    "       \"arai/ura\",\"isii/ura\"]\n",
    "\n",
    "'''\n",
    "#他人受入率用のテスト配列\n",
    "omote=[\"saitouhide/omote\",\"saitouryou/omote\",\n",
    "      \"sakuma/omote\",\"tanaka/omote\",\"tokuyama/omote\",\"watanabe/omote\",\n",
    "      \"yamaguchi/omote\"]\n",
    "ura=[\"saitouhide/ura\",\"saitouryou/ura\",\n",
    "      \"sakuma/ura\",\"tanaka/ura\",\"tokuyama/ura\",\"watanabe/ura\",\n",
    "      \"yamaguchi/ura\"]\n",
    "'''\n",
    "target_omote=[]\n",
    "target_ura=[]\n",
    "laplace5=[[-1,-3,-4,-3,-1],\n",
    "         [-3,0,6,0,-3],\n",
    "         [-4,6,20,6,-4],\n",
    "         [-3,0,6,0,-3],\n",
    "         [-1,-3,-4,-3,-1]]\n",
    "laplace3=[[1,1,1],\n",
    "         [1,-8,1],\n",
    "         [1,1,1]]\n",
    "passpercent=[]\n",
    "notpasspercent=[]\n",
    "omotepercent=[]\n",
    "urapercent=[]\n",
    "for k in range(7):#変更必要\n",
    "    for i in range(10):\n",
    "        target_omote.append(\"./graytest/\"+str(omote[k])+\"/\"+str(i)+\".jpg\")#変更必要\n",
    "        target_ura.append(\"./graytest/\"+str(ura[k])+\"/\"+str(i)+\".jpg\")#変更必要\n",
    "\n",
    "\n",
    "im_rows = 256 #変更必要\n",
    "im_cols = 256 #変更必要\n",
    "im_color = 1 #変更必要\n",
    "in_shape = (im_rows, im_cols, im_color)\n",
    "nb_classes = 16 #変更必要\n",
    "\n",
    "#他人受入率用のラベル\n",
    "\n",
    "LABELS=[\"江波戸の表\",\"江波戸の裏\",\"奥谷君の表\",\"奥谷君の裏\",\n",
    "       \"栃窪先生の表\",\"栃窪先生の裏\",\"中村君の表\",\"中村君の裏\",\n",
    "       \"後藤さんの表\",\"後藤さんの裏\",\"三村君の表\",\"三村君の裏\",\n",
    "       \"新井さんの表\",\"新井さんの裏\",\"石井さんの表\",\"石井さんの裏\"]\n",
    "\n",
    "model = get_model(in_shape, nb_classes)\n",
    "model.load_weights('./hdf/num16edges5light256pix.hdf5')#変更必要\n",
    "\n",
    "def check_photo(path):\n",
    "    img=cv2.imread(path)\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    karnel=np.array(laplace3,np.float64)\n",
    "    #img=Image.open(path)\n",
    "    img=cv2.filter2D(img,-1,karnel)\n",
    "    img=cv2.resize(img,(im_rows,im_cols))\n",
    "    plt.imshow(img,cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "    x=np.asarray(img)\n",
    "    x=x.reshape(-1,im_rows,im_cols,im_color)\n",
    "    x=x/255\n",
    "    \n",
    "    #予測\n",
    "    pre=model.predict([x])[0]#画像の予測\n",
    "    idx=pre.argmax()\n",
    "    #per=(pre[idx]*100)\n",
    "    per=int(pre[idx]*100)\n",
    "    if per<99 and (\"omote\" in path):\n",
    "        omotepercent.append(per)\n",
    "    elif per<99 and (\"ura\" in path):\n",
    "        urapercent.append(per)\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    return(idx,per)\n",
    "\n",
    "def check_photo_str(path):\n",
    "    idx,per=check_photo(path)\n",
    "    if per>=99:\n",
    "        print(\"この写真は、\",LABELS[idx],\"です。\")\n",
    "        print(\"可能性は、\",per,\"%です。\")\n",
    "        passpercent.append(per)\n",
    "    else:\n",
    "        print('\\033[31m'+\"可能性が\",per,\"%なので認証できません。\"+'\\033[31m')\n",
    "        print(\"認証の結果は\",LABELS[idx],\"でした。\")\n",
    "        notpasspercent.append(per)\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    number=[9,19,29,39,49,59,69,79,89,99,109,119,129,139,149]\n",
    "    for i in range(70):\n",
    "        print(\"\\nここからは\"+str(i)+\"番目の写真です\")\n",
    "        check_photo_str(target_omote[i])\n",
    "        for l in range(15):\n",
    "            if i==number[l]:\n",
    "                print(\"================================================\")\n",
    "                print(\"テスト対象の人が変わります\")\n",
    "                print(\"================================================\")\n",
    "    for i in range(70):\n",
    "        print(\"\\nここからは\"+str(i)+\"番目の写真です\")\n",
    "        check_photo_str(target_ura[i])\n",
    "        for l in range(15):\n",
    "            if i==number[l]:\n",
    "                print(\"================================================\")\n",
    "                print(\"テスト対象の人が変わります\")\n",
    "                print(\"================================================\")\n",
    "    print(passpercent)\n",
    "    print(notpasspercent)\n",
    "    print(\"閾値以上で識別したテスト数\"+str(len(passpercent)))\n",
    "    print(\"閾値未満で識別したテスト数\"+str(len(notpasspercent)))\n",
    "    print(\"表の手だけで閾値未満で識別したテスト数\"+str(len(omotepercent)))\n",
    "    print(\"裏の手だけで閾値未満で識別したテスト数\"+str(len(urapercent)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
